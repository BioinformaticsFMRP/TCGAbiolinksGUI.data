---
title: "Supporting data for the TCGAbiolinksGUI package"
author: "Tiago Chedraoui Silva, Tathiane Malta, Houtan Noushmehr"
date: "`r Sys.Date()`"
output: 
    BiocStyle::html_document:
      highlight: tango
      toc: yes
      fig_caption: yes     
      toc_depth: 3
      toc_float:
        collapsed: yes
      number_sections: true
    editor_options: 
      chunk_output_type: inline
references:
vignette: >
  \usepackage[utf8]{inputenc}
  %\VignetteIndexEntry{Supporting data for the TCGAbiolinksGUI package}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: inline
bibliography: bibliography.bib    
---   

# Introduction

This document provides an introduction of the `r BiocStyle::Biocpkg("TCGAbiolinksGUI.data")`, which contains 
supporting data for `r BiocStyle::Biocpkg("TCGAbiolinksGUI")` [@silva2017tcgabiolinksgui]. 

This package contains the following objects:

- glioma.gcimp.model  
- glioma.idh.model
- glioma.idhmut.model
- glioma.idhwt.model 

## Installing TCGAbiolinksGUI.data

You can install the package from Bioconductor:
```{r, eval = FALSE}
source("https://www.bioconductor.org/biocLite.R")
bioLite("TCGAbiolinksGUI.data")
```

Or from github:
```{r, eval = FALSE}
devtools::install_github(repo = "BioinformaticsFMRP/TCGAbiolinksGUI.data")
```

Load the package:

```{r, eval = TRUE}
library(TCGAbiolinksGUI.data)
```


# Contents

## Creating list of GDC projects

The code below access the NCI's Genomic Data Commons (GDC) and get the list of available datasets for TCGA and TARGET projects.

```{r, eval=FALSE, include=TRUE}
# Defining parameters
getGDCdisease <- function(){
  projects <- TCGAbiolinks:::getGDCprojects()
  projects <- projects[projects$id != "FM-AD",]
  disease <-  projects$project_id
  idx <- grep("disease_type",colnames(projects))
  names(disease) <-  paste0(projects[[idx]], " (",disease,")")
  disease <- disease[sort(names(disease))]
  return(disease)
}
```

This data is in saved in the GDCdisease object.
```{r}
data(GDCdisease)
head(GDCdisease)
```

## List of MAF files

The code below downloads a manifest of open TCGA MAF files available in the NCI's Genomic Data Commons (GDC).
```{r, eval=FALSE, include=TRUE}
getMafTumors <- function(){
  root <- "https://gdc-api.nci.nih.gov/data/"
  maf <- fread("https://gdc-docs.nci.nih.gov/Data/Release_Notes/Manifests/GDC_open_MAFs_manifest.txt",
               data.table = FALSE, verbose = FALSE, showProgress = FALSE)
  tumor <- unlist(lapply(maf$filename, function(x){unlist(str_split(x,"\\."))[2]}))
  proj <- TCGAbiolinks:::getGDCprojects()
  
  disease <-  gsub("TCGA-","",proj$project_id)
  idx <- grep("disease_type",colnames(proj))
  names(disease) <-  paste0(proj[[idx]], " (",proj$project_id,")")
  disease <- sort(disease)
  ret <- disease[disease %in% tumor]
  return(ret)
}
```

This data is in saved in the maf.tumor object.
```{r}
data(maf.tumor)
head(maf.tumor)
```


## Creating Training models

Based on the article data from the article "Molecular Profiling Reveals Biologically Discrete Subsets and Pathways of Progression in Diffuse Glioma" (www.cell.com/cell/abstract/S0092-8674(15)01692-X) [@Cell]
we created a traning model to predict Glioma classes based on DNA methylation signatures.

For the code to be executed we load the required libraries:
```{r, eval=FALSE, include=TRUE}
#-----------------------------------------------------------------------------
# Classify Metabolism Samples into TCGA molecular subtypes
# Original code created by: Tathi Malta
# Adapted by: Tiago Silva
#-----------------------------------------------------------------------------
library(readr)
library(readxl)
library(dplyr)
library(caret)
library(randomForest)
library(doMC)
library(e1071)
# Confirm seed is set
set.seed(210)

# register cores for doMC
registerDoMC(cores = parallel::detectCores())
```

The next steps will download from the article: the DNA methylation data for glioma samples, samples metadata, and 
DNA methylation signatures. Probes metadata information are downloaded from http://zwdzwd.io/InfiniumAnnotation

```{r, eval=FALSE, include=TRUE}
#-----------------------------------------------------------------------------
# Load data used for models
#-----------------------------------------------------------------------------
# 1) DNA methylation matrix
file <- "https://tcga-data.nci.nih.gov/docs/publications/lgggbm_2016/LGG.GBM.meth.txt"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
LGG.GBM <- as.data.frame(readr::read_tsv(basename(file)))
rownames(LGG.GBM) <- LGG.GBM$Composite.Element.REF
idx <- grep("TCGA",colnames(LGG.GBM))
colnames(LGG.GBM)[idx] <- substr(colnames(LGG.GBM)[idx], 1, 12) #fix sample id
```

We will get metadata with samples molecular subtypes from the paper.  (www.cell.com/cell/abstract/S0092-8674(15)01692-X) [@Cell]

```{r, eval=FALSE, include=TRUE}
file <- "http://www.cell.com/cms/attachment/2045372863/2056783242/mmc2.xlsx"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
metadata <-  read_excel(basename(file), sheet = "S1A. TCGA discovery dataset", skip = 1) # pdata (TableS1)
```

We will retrieve all the manifest files for DNA methylation array. That will be used 
to remove probes that should be masked from the training.
```{r, eval=FALSE, include=TRUE}
file <- "http://zwdzwd.io/InfiniumAnnotation/current/EPIC/EPIC.manifest.rda"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
load(basename(file))

file <- "http://zwdzwd.io/InfiniumAnnotation/current/EPIC/EPIC.manifest.hg38.rda"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
load(basename(file))

file <- "http://zwdzwd.io/InfiniumAnnotation/current/hm450/hm450.manifest.hg38.rda"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
load(basename(file))

file <- "http://zwdzwd.io/InfiniumAnnotation/current/hm450/hm450.manifest.rda"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
load(basename(file))
```

Retrieve probe signatures.
```{r, eval=FALSE, include=TRUE}
# 4) Probes singature for IDH mutation
file <- "https://tcga-data.nci.nih.gov/docs/publications/lgggbm_2015/PanGlioma_MethylationSignatures.xlsx"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
```


With the data and metadata available we will create one model  for each signature. 
The code below simply select the DNA methylation values for a given set ofsignatures
and using the labels for each samples a Random forest model is created.
The models created are:

## RF to classify between IDHmut and IDHwt
- trainingset: whole TCGA panglioma cohort
- probes signature: "1,300 pan-glioma tumor specific"
- groups: LGm1, LGm2, LGm3, LGm4, LGm5, LGm6
- metadata column: Pan-Glioma DNA Methylation Cluster

We will start by preparing the training data. The DNA methylation matrix will be subset to the DNA methylation
signatures and samples with classification.

```{r, eval=FALSE, include=TRUE}
sheets <- c("1,300 pan-glioma tumor specific")
trainingset <- grep("mut|wt",unique(metadata$`IDH-specific DNA Methylation Cluster`),value = T)
trainingcol <- c("Pan-Glioma DNA Methylation Cluster")
plat <- "450K"
signature.probes <-  read_excel("PanGlioma_MethylationSignatures.xlsx",  sheet = sheets)  %>% pull(1) 
samples <- dplyr::filter(metadata, `IDH-specific DNA Methylation Cluster` %in% trainingset)
RFtrain <- LGG.GBM[signature.probes, colnames(LGG.GBM) %in% as.character(samples$Case)] %>% na.omit 
```

Probes that should be masked, will be removed.
```{r, eval=FALSE, include=TRUE}
RFtrain <- RFtrain[!hm450.manifest.hg38[rownames(RFtrain)]$MASK.general,]
```

We will merge the samples with their classification. In the end we will have samples in the row, probes and classification as columns
```{r, eval=FALSE, include=TRUE}
trainingdata <- t(RFtrain)
trainingdata <- merge(trainingdata, metadata[,c("Case", trainingcol[model])], by.x=0,by.y="Case", all.x=T)
rownames(trainingdata) <- as.character(trainingdata$Row.names)
trainingdata$Row.names <- NULL
```

With data prepared we will start the RF traning by selecting tuning the mtry argument.
```{r, eval=FALSE, include=TRUE}
# set up k-fold cross validation
fitControl <- trainControl(## 10-fold CV
  method = "repeatedcv",
  number = 10,
  verboseIter = TRUE,
  repeats = 10)

nfeat <- ncol(trainingdata)
trainingdata[,trainingcol] <-  factor(trainingdata[,trainingcol])
mtryVals <- floor(sqrt(nfeat))
for(i in floor(seq(sqrt(nfeat), nfeat/2, by = 2 * sqrt(nfeat)))) {
  print(i)
  x <- as.data.frame(tuneRF(trainingdata[,-grep(trainingcol[model],colnames(trainingdata))], 
                            trainingdata[,trainingcol[model]], 
                            stepFactor=2,
                            plot= FALSE,
                            mtryStart = i))
  mtryVals <- unique(c(mtryVals, x$mtry[which (x$OOBError  == min(x$OOBError))]))
}
mtryGrid <- data.frame(.mtry=mtryVals)
# Confirm seed again
set.seed(420)
```

We will use the training data to create our Random forest model
```{r, eval=FALSE, include=TRUE}
glioma.idh.model <- train(y = trainingdata[,trainingcol], # variable to be trained on
                          x = trainingdata[,-grep(trainingcol,colnames(trainingdata))],
                          data = trainingdata, # Data we are using
                          method = "rf", # Method we are using
                          trControl = fitControl, # How we validate
                          ntree = 5000, # number of trees
                          importance = TRUE, # calculate varible importance
                          tuneGrid = mtryGrid, # set mtrys
)
```

The IDH model are saved in  glioma.idh.model object.
```{r}
data(glioma.idh.model)
glioma.idh.model
```



### RF to classify IDHmut specific clusters
- trainingset: TCGA IDHmut only
- probes signature: "1,308 IDHmutant tumor specific "
- groups: IDHmut-K1, IDHmut-K2, IDHmut-K3
- metadata column: IDH-specific DNA Methylation Cluster


The IDHmut model  are saved in  glioma.idhmut.model object.
```{r}
data(glioma.idhmut.model)
glioma.idhmut.model
```



### RF to classify between G-CIMP-low and G-CIMP-high 
- trainingset: TCGA IDHmut-K1 and IDHmut-K2 only
- probes signature: "163  probes that define each TC"
- groups: G-CIMP-low, G-CIMP-high
- metadata column: Supervised DNA Methylation Cluster

The G-CIMP model are saved in  glioma.gcimp.model object.
```{r}
data("glioma.gcimp.model")
glioma.gcimp.model
```

### RF to classify IDHwt specific clusters 
- trainingset: TCGA IDHwt only
- probes signature: "914 IDHwildtype tumor specific "
- groups: IDHwt-K1, IDHwt-K2, IDHwt-K3
- metadata column:  IDH-specific DNA Methylation Cluster

Note: In this case, samples classified into IDHwt-K3 
should be further subdivided by grade.


The IDHwt specific model which classifies are saved in  glioma.idh.model object.
```{r}
data("glioma.idhwt.model")
glioma.idhwt.model
```


### Code to create all models
```{r, eval=FALSE, include=TRUE}
sheets <- c("1,300 pan-glioma tumor specific",
            "1,308 IDHmutant tumor specific ",
            "163  probes that define each TC",
            "914 IDHwildtype tumor specific ")

trainingset <- list(grep("mut|wt",unique(metadata$`IDH-specific DNA Methylation Cluster`),value = T), 
                    grep("mut",unique(metadata$`IDH-specific DNA Methylation Cluster`),value = T), # TCGA mut only
                    c("IDHmut-K1","IDHmut-K2"),
                    grep("wt",unique(metadata$`IDH-specific DNA Methylation Cluster`),value = T)) # TCGA IDHwt only

trainingcol <- c("Pan-Glioma DNA Methylation Cluster",
                 "IDH-specific DNA Methylation Cluster",
                 "Supervised DNA Methylation Cluster",
                 "IDH-specific DNA Methylation Cluster")

# We will consider 450K and EPIC platform as the have different probes
# and probes that should be masked (http://zwdzwd.github.io/InfiniumAnnotation)
for(plat in c("EPIC","450K")){
  for(model in 1:4){ 
    message(paste0("Platform: ", plat,"\nModel:", model," (", sheets[model],")"))
    signature.probes <-  read_excel(basename(file),  sheet = sheets[model])  %>% pull(1) 
    samples <- dplyr::filter(metadata, `IDH-specific DNA Methylation Cluster` %in% trainingset[[model]])
    
    # Creating Training SET
    RFtrain <- LGG.GBM[signature.probes, colnames(LGG.GBM) %in% as.character(samples$Case)] %>% na.omit 
    if(plat == "450K"){
      RFtrain <- RFtrain[!hm450.manifest.hg38[rownames(RFtrain)]$MASK.general,]
    } else if(plat == "EPIC"){
      # Keep only probes in the EPIC array that should not be masked
      RFtrain <- RFtrain[rownames(RFtrain) %in% names(EPIC.manifest.hg38),]
      RFtrain <- RFtrain[!EPIC.manifest.hg38[rownames(RFtrain)]$MASK.general,]
    }
    trainingdata <- t(RFtrain)
    trainingdata <- merge(trainingdata, metadata[,c("Case", trainingcol[model])], by.x=0,by.y="Case", all.x=T)
    rownames(trainingdata) <- as.character(trainingdata$Row.names)
    trainingdata$Row.names <- NULL
    save(trainingdata, file = paste0(plat,"_trainingdata",gsub(" ","_",sheets[model]),".Rda"), compress = "xz")
    
    # register cores for doMC
    registerDoMC(cores = parallel::detectCores())
    # set up k-fold cross validation
    fitControl <- trainControl(## 10-fold CV
      method = "repeatedcv",
      number = 10,
      verboseIter = TRUE,
      repeats = 10)
    
    
    set.seed(42)  # Set your seed so your work is repeatable
    
    # Create a subset of your data to train your model on.  This makes sure you have
    # equal representation of the 'papercluster' groups in your training set
    inTraining <- createDataPartition(trainingdata[,trainingcol[model]], p=0.8, list=FALSE, times=1)
    
    myTrain <- trainingdata[inTraining, ]  # Training Set
    myTest <- trainingdata[-inTraining, ]   # Testing Set
    # Confirm seed is set
    set.seed(210)
    # set values for mtry
    # mtry is the "Number of variables randomly sampled as candidates at each split"
    # traditionally for classification you use the sqrt of the number of variables
    # but here we try a range of mtry values to find the best parameters for our model
    
    nfeat <- ncol(trainingdata)
    trainingdata[,trainingcol[model]] <-  factor(trainingdata[,trainingcol[model]])
    mtryVals <- floor(sqrt(nfeat))
    for(i in floor(seq(sqrt(nfeat), nfeat/2, by = 2 * sqrt(nfeat)))) {
      print(i)
      x <- as.data.frame(tuneRF(trainingdata[,-grep(trainingcol[model],colnames(trainingdata))], 
                                trainingdata[,trainingcol[model]], 
                                stepFactor=2,
                                plot= FALSE,
                                mtryStart = i))
      mtryVals <- unique(c(mtryVals, x$mtry[which (x$OOBError  == min(x$OOBError))]))
    }
    mtryGrid <- data.frame(.mtry=mtryVals)
    # Confirm seed again
    set.seed(420)
    
    message("Testing if test and train data have all groups")
    stopifnot(all(unique(myTest[,trainingcol[model]]) %in% unique(myTrain[,trainingcol[model]])))
    groups <- rbind(table(trainingdata[,trainingcol[model]]),table(myTrain[,trainingcol[model]]),table(myTest[,trainingcol[model]]))
    rownames(groups) <- c("All groups", "Train","Test")
    print(knitr::kable(groups))
    
    message("Training...")
    message(paste0("Training set - 80%: ", nrow(trainingdata), " samples", " vs ", ncol(trainingdata), " probes "))
    train.model <- train(y = trainingdata[,trainingcol[model]], # variable to be trained on
                         x = trainingdata[,-grep(trainingcol[model],colnames(trainingdata))],
                         data = trainingdata, # Data we are using
                         method = "rf", # Method we are using
                         trControl = fitControl, # How we validate
                         # We created this object above
                         ntree = 5000, # number of trees
                         # is dependent on training data size
                         importance = TRUE, # calculate varible importance
                         # can be omitted to speed up calc
                         tuneGrid = mtryGrid, # set mtrys
                         #subset = inTraining # define training set #comment when train with 100% of samples
    )
    save(train.model,mtryGrid,fitControl,trainingdata,inTraining, myTrain,myTest,
         file = paste0(plat,"_RF_model_100_",gsub(" ","_",sheets[model]),".Rda"), compress = "xz")
  }
}
```


## EPIC probes to remove

The list of probes to be removed from EPIC array due to differences in library versions were taken from
https://support.illumina.com/downloads/infinium-methylationepic-v1-0-product-files.html (Infinium MethylationEPIC v1.0 Missing Legacy CpG (B3 vs. B2) Annotation File)

```{r}
data("probes2rm")
head(probes2rm)
```
# Session Information
******
```{r sessionInfo}
sessionInfo()
```

# References
