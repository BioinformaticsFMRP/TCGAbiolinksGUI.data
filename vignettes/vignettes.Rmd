---
title: "TCGAbiolinksGUI: Supporting data for the TCGAbiolinksGUI package"
author: "Tiago Chedraoui Silva, Simon Coetzee, Lijing Yao, Peggy Farnham, Hui Shen, Peter Laird, Houtan Noushmehr, Ben Berman"
date: "`r Sys.Date()`"
output: 
    BiocStyle::html_document:
      highlight: tango
      toc: yes
      fig_caption: yes     
      toc_depth: 3
      toc_float:
        collapsed: yes
      number_sections: true
    editor_options: 
      chunk_output_type: inline
references:
vignette: >
  \usepackage[utf8]{inputenc}
  %\VignetteIndexEntry{TCGAbiolinksGUI: Supporting data for the TCGAbiolinksGUI package}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: inline
bibliography: bibliography.bib    
---   

# Introduction

This document provides an introduction of the `r BiocStyle::Biocpkg("TCGAbiolinksGUI.data")`, which contains 
supporting data for `r BiocStyle::Biocpkg("TCGAbiolinksGUI")` [@silva2017tcgabiolinksgui]. `r BiocStyle::Biocpkg("TCGAbiolinksGUI")`.
This package contains the following objects:
  - glioma.gcimp.model  
  - glioma.idh.model
  - glioma.idhmut.model
  - glioma.idhwt.model 

## Installing and loading ELMER.data

To install this package, start R and enter

```{r, eval = FALSE}
devtools::install_github(repo = "BioinformaticsFMRP/TCGAbiolinksGUI.data")
library("TCGAbiolinksGUI.data")
```

# Contents

## Creating Training models

Based on the article data from the article "Molecular Profiling Reveals Biologically Discrete Subsets and Pathways of Progression in Diffuse Glioma" (www.cell.com/cell/abstract/S0092-8674(15)01692-X) [@Cell]
we created a traning model to predict Glioma classes based on DNA methylation signatures.

```{r, eval=FALSE, include=TRUE}
#-----------------------------------------------------------------------------
# Classify Metabolism Samples into TCGA molecular subtypes
# Original code created by: Tathi Malta
# Adapted by: Tiago Silva
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
# Load libraries
#-----------------------------------------------------------------------------
library(readr)
library(readxl)
library(dplyr)
library(caret)
library(randomForest)
library(doMC)
library(e1071)

#-----------------------------------------------------------------------------
# Load data used for models
#-----------------------------------------------------------------------------
# 1) DNA methylation matrix
file <- "https://tcga-data.nci.nih.gov/docs/publications/lgggbm_2016/LGG.GBM.meth.txt"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
LGG.GBM <- as.data.frame(readr::read_tsv(basename(file)))
rownames(LGG.GBM) <- LGG.GBM$Composite.Element.REF
idx <- grep("TCGA",colnames(LGG.GBM))
colnames(LGG.GBM)[idx] <- substr(colnames(LGG.GBM)[idx], 1, 12) #fix sample id

# 2) Get metadata
file <- "http://www.cell.com/cms/attachment/2045372863/2056783242/mmc2.xlsx"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
metadata <-  read_excel(basename(file), sheet = "S1A. TCGA discovery dataset", skip = 1) # pdata (TableS1)

# 3) hm450 and EPIC probes metadata information 
file <- "http://zwdzwd.io/InfiniumAnnotation/current/EPIC/EPIC.manifest.rda"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
load(basename(file))

file <- "http://zwdzwd.io/InfiniumAnnotation/current/EPIC/EPIC.manifest.hg38.rda"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
load(basename(file))

file <- "http://zwdzwd.io/InfiniumAnnotation/current/hm450/hm450.manifest.hg38.rda"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
load(basename(file))

file <- "http://zwdzwd.io/InfiniumAnnotation/current/hm450/hm450.manifest.rda"
if(!file.exists(basename(file))) downloader::download(file,basename(file))
load(basename(file))

# 4) Probes singature for IDH mutation
file <- "https://tcga-data.nci.nih.gov/docs/publications/lgggbm_2015/PanGlioma_MethylationSignatures.xlsx"
if(!file.exists(basename(file))) downloader::download(file,basename(file))

#-------------------------------------------------------------
# Create one model for each signature
#-------------------------------------------------------------
# 1) RF to classify btw IDHmut and IDHwt:
#   - trainingset: whole TCGA panglioma cohort
#   - probes signature: "1,300 pan-glioma tumor specific"
#   - grups: LGm1, LGm2, LGm3, LGm4, LGm5, LGm6
#   - metadata column: Pan-Glioma DNA Methylation Cluster
#-------------------------------------------------------------
# 2) RF to classify IDHmut specific clusters (Fig S3A):
#   - trainingset: TCGA IDHmut only
#   - probes signature: "1,308 IDHmutant tumor specific "
#   - grups: IDHmut-K1, IDHmut-K2, IDHmut-K3
#   - metadata column: IDH-specific DNA Methylation Cluster
#-------------------------------------------------------------
# 3) RF to classify btw G-CIMP-low and G-CIMP-high (Fig S3C):
#   - trainingset: TCGA IDHmut-K1 and IDHmut-K2 only
#   - probes signature: "163  probes that define each TC"
#   - grups: G-CIMP-low, G-CIMP-high
#   - metadata column: Supervised DNA Methylation Cluster
#-------------------------------------------------------------
# 4) RF to classify IDHwt specific clusters (Fig S4A/B):
#   - trainingset: TCGA IDHwt only
#   - probes signature: "914 IDHwildtype tumor specific "
#   - grups: IDHwt-K1, IDHwt-K2, IDHwt-K3
#   - metadata column:  IDH-specific DNA Methylation Cluster
# Note: In this case, samples classified into IDHwt-K3 
#       should be further subdivided by grade.
#-------------------------------------------------------------

sheets <- c("1,300 pan-glioma tumor specific",
            "1,308 IDHmutant tumor specific ",
            "163  probes that define each TC",
            "914 IDHwildtype tumor specific ")

trainingset <- list(grep("mut|wt",unique(metadata$`IDH-specific DNA Methylation Cluster`),value = T), 
                    grep("mut",unique(metadata$`IDH-specific DNA Methylation Cluster`),value = T), # TCGA mut only
                    c("IDHmut-K1","IDHmut-K2"),
                    grep("wt",unique(metadata$`IDH-specific DNA Methylation Cluster`),value = T)) # TCGA IDHwt only

trainingcol <- c("Pan-Glioma DNA Methylation Cluster",
                 "IDH-specific DNA Methylation Cluster",
                 "Supervised DNA Methylation Cluster",
                 "IDH-specific DNA Methylation Cluster")

# We will consider 450K and EPIC platform as the have different probes
# and probes that should be masked (http://zwdzwd.github.io/InfiniumAnnotation)
for(plat in c("EPIC","450K")){
  for(model in 1:4){ 
    if(file.exists(paste0(plat,"_RF_model_80_",gsub(" ","_",sheets[model]),".Rda"))) next
    message(paste0("Platform: ", plat,"\nModel:", model," (", sheets[model],")"))
    signature.probes <-  read_excel(basename(file),  sheet = sheets[model])  %>% pull(1) 
    samples <- dplyr::filter(metadata, `IDH-specific DNA Methylation Cluster` %in% trainingset[[model]])
    
    # Creating Training SET
    RFtrain <- LGG.GBM[signature.probes, colnames(LGG.GBM) %in% as.character(samples$Case)] %>% na.omit 
    if(plat == "450K"){
      RFtrain <- RFtrain[!hm450.manifest.hg38[rownames(RFtrain)]$MASK.general,]
    } else if(plat == "EPIC"){
      # Keep only probes in the EPIC array that should not be masked
      RFtrain <- RFtrain[rownames(RFtrain) %in% names(EPIC.manifest.hg38),]
      RFtrain <- RFtrain[!EPIC.manifest.hg38[rownames(RFtrain)]$MASK.general,]
    }
    trainingdata <- t(RFtrain)
    trainingdata <- merge(trainingdata, metadata[,c("Case", trainingcol[model])], by.x=0,by.y="Case", all.x=T)
    rownames(trainingdata) <- as.character(trainingdata$Row.names)
    trainingdata$Row.names <- NULL #  430 samples, 856 probes, 1 groups (430 857)
    save(trainingdata, file = paste0(plat,"_trainingdata",gsub(" ","_",sheets[model]),".Rda"), compress = "xz")
    
    # register cores for doMC
    registerDoMC(cores = parallel::detectCores())
    # set up k-fold cross validation
    fitControl <- trainControl(## 10-fold CV
      method = "repeatedcv",
      number = 10,
      verboseIter = TRUE,
      ## repeated ten times
      repeats = 10)
    # you may additionally, if you wish use a different method, for validating your
    # model parameters, such as oob (Out of Bag).  oob is faster.
    
    # Set your seed so your work is repeatable
    set.seed(42)
    # Create a subset of your data to train your model on.  This makes sure you have
    # equal representation of the 'papercluster' groups in your training set
    inTraining <- createDataPartition(trainingdata[,trainingcol[model]], p=0.8, list=FALSE, times=1)
    # Training Set
    myTrain <- trainingdata[inTraining, ] 
    # Testing Set
    myTest <- trainingdata[-inTraining, ] 
    # Confirm seed is set
    set.seed(210)
    # set values for mtry
    # mtry is the "Number of variables randomly sampled as candidates at each split"
    # traditionally for classification you use the sqrt of the number of variables
    # but here we try a range of mtry values to find the best parameters for our model
    
    nfeat <- ncol(trainingdata)
    trainingdata[,trainingcol[model]] <-  factor(trainingdata[,trainingcol[model]])
    mtryVals <- floor(sqrt(nfeat))
    for(i in floor(seq(sqrt(nfeat), nfeat/2, by = 2 * sqrt(nfeat)))) {
      print(i)
      x <- as.data.frame(tuneRF(trainingdata[,-grep(trainingcol[model],colnames(trainingdata))], 
                                trainingdata[,trainingcol[model]], 
                                stepFactor=2,
                                plot= FALSE,
                                mtryStart = i))
      mtryVals <- unique(c(mtryVals, x$mtry[which (x$OOBError  == min(x$OOBError))]))
    }
    mtryGrid <- data.frame(.mtry=mtryVals)
    # Confirm seed again
    set.seed(420)
    
    message("Testing if test and train data have all groups")
    stopifnot(all(unique(myTest[,trainingcol[model]]) %in% unique(myTrain[,trainingcol[model]])))
    groups <- rbind(table(trainingdata[,trainingcol[model]]),table(myTrain[,trainingcol[model]]),table(myTest[,trainingcol[model]]))
    rownames(groups) <- c("All groups", "Train","Test")
    print(knitr::kable(groups))
    
    message("Training...")
    message(paste0("Training set - 80%: ", nrow(trainingdata), " samples", " vs ", ncol(trainingdata), " probes "))
    train.model <- train(y = trainingdata[,trainingcol[model]], # variable to be trained on
                   x = trainingdata[,-grep(trainingcol[model],colnames(trainingdata))],
                   data = trainingdata, # Data we are using
                   method = "rf", # Method we are using
                   trControl = fitControl, # How we validate
                   # We created this object above
                   ntree = 5000, # number of trees
                   # is dependent on training data size
                   importance = TRUE, # calculate varible importance
                   # can be omitted to speed up calc
                   tuneGrid = mtryGrid, # set mtrys
                   #subset = inTraining # define training set #comment when train with 100% of samples
    )
    save(train.model,mtryGrid,fitControl,trainingdata,inTraining, myTrain,myTest,
         file = paste0(plat,"_RF_model_100_",gsub(" ","_",sheets[model]),".Rda"), compress = "xz")
  }
}
```
# Session Information
******
```{r sessionInfo}
sessionInfo()
```

# References
